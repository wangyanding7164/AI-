# train_mcts.py
import numpy as np
import torch
from tqdm import tqdm
import matplotlib.pyplot as plt
import os
import sys
from datetime import datetime
import pickle

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.mcts_ai import MCTSAI
from models.rule_based_ai import RuleBasedAI
from models.dqn_ai import DQNAgent


class MCTSTrainingEnv:
    """MCTSè®­ç»ƒç¯å¢ƒ"""

    def __init__(self, board_size=9):
        self.board_size = board_size
        self.reset()

    def reset(self):
        self.board = np.zeros((self.board_size, self.board_size), dtype=int)
        self.current_player = 1
        self.done = False
        self.winner = None
        self.history = []
        return self.board.copy()

    def get_valid_moves(self):
        n = self.board_size
        valid_moves = np.zeros(n * n, dtype=int)
        for y in range(n):
            for x in range(n):
                if self.board[y][x] == 0:
                    action = y * n + x
                    valid_moves[action] = 1
        return valid_moves

    def step(self, action, player):
        """æ‰§è¡Œä¸€æ­¥"""
        n = self.board_size
        x, y = action % n, action // n

        if not (0 <= x < n and 0 <= y < n and self.board[y][x] == 0):
            return self.board.copy(), 0, True, {}

        self.board[y][x] = player
        self.history.append((action, player))

        # æ£€æŸ¥è·èƒœ
        if self.check_win(x, y, player):
            self.done = True
            self.winner = player
            reward = 1.0
        elif np.all(self.board != 0):  # å¹³å±€
            self.done = True
            self.winner = 0
            reward = 0.1
        else:
            reward = 0.0
            self.current_player = 3 - player

        return self.board.copy(), reward, self.done, {}

    def check_win(self, x, y, player):
        """æ£€æŸ¥è·èƒœ"""
        directions = [(1, 0), (0, 1), (1, 1), (1, -1)]

        for dx, dy in directions:
            count = 1

            # æ­£å‘
            for i in range(1, 5):
                nx, ny = x + dx * i, y + dy * i
                if 0 <= nx < self.board_size and 0 <= ny < self.board_size and self.board[ny][nx] == player:
                    count += 1
                else:
                    break

            # åå‘
            for i in range(1, 5):
                nx, ny = x - dx * i, y - dy * i
                if 0 <= nx < self.board_size and 0 <= ny < self.board_size and self.board[ny][nx] == player:
                    count += 1
                else:
                    break

            if count >= 5:
                return True

        return False

    def get_state(self):
        return self.board.copy()


def train_mcts_with_opponent(config):
    """ç”¨æŒ‡å®šå¯¹æ‰‹è®­ç»ƒMCTS"""
    print("=" * 60)
    print(f"è®­ç»ƒMCTS AI (å¯¹æ‰‹: {config['opponent_type']})")
    print("=" * 60)

    # åˆ›å»ºMCTS AI
    mcts_ai = MCTSAI(
        board_size=config['board_size'],
        player=1,
        iterations=config['iterations_per_move'],
        debug=config.get('debug', False)
    )

    # åˆ›å»ºå¯¹æ‰‹
    if config['opponent_type'] == 'rule_based':
        opponent = RuleBasedAI(
            player=2,
            board_size=config['board_size'],
            aggression=config.get('opponent_aggression', 0.5)
        )
    elif config['opponent_type'] == 'dqn':
        opponent = DQNAgent(
            board_size=config['board_size'],
            player=2,
            epsilon=0.01  # æ¨ç†æ¨¡å¼
        )
        # åŠ è½½è®­ç»ƒå¥½çš„DQN
        dqn_path = config.get('dqn_model_path', 'saved_models/dqn_final.pth')
        if os.path.exists(dqn_path):
            opponent.load(dqn_path)
            print(f"âœ… åŠ è½½DQNå¯¹æ‰‹: {dqn_path}")
        else:
            print(f"âŒ DQNæ¨¡å‹ä¸å­˜åœ¨: {dqn_path}")
            return None
    else:
        print(f"âŒ æœªçŸ¥å¯¹æ‰‹ç±»å‹: {config['opponent_type']}")
        return None

    # è®­ç»ƒç»Ÿè®¡
    stats = {
        'games': [],
        'mcts_wins': [],
        'opponent_wins': [],
        'draws': [],
        'avg_moves': [],
        'training_time': []
    }

    # åˆ›å»ºä¿å­˜ç›®å½•
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    save_dir = os.path.join(config['save_dir'], f"mcts_vs_{config['opponent_type']}_{timestamp}")
    os.makedirs(save_dir, exist_ok=True)

    print(f"ä¿å­˜ç›®å½•: {save_dir}")
    print(f"è®­ç»ƒå±€æ•°: {config['total_games']}")
    print(f"MCTSæ¯æ­¥æœç´¢æ¬¡æ•°: {config['iterations_per_move']}")
    print(f"å¯¹æ‰‹: {config['opponent_type']}")

    mcts_wins = 0
    opponent_wins = 0
    draws = 0

    for game_idx in tqdm(range(config['total_games']), desc="è®­ç»ƒè¿›åº¦"):
        start_time = datetime.now()

        env = MCTSTrainingEnv(config['board_size'])
        state = env.reset()
        done = False

        # éšæœºå†³å®šå…ˆæ‰‹
        mcts_first = np.random.random() < 0.5
        mcts_player = 1 if mcts_first else 2
        opponent_player = 2 if mcts_first else 1

        moves = 0
        max_moves = config['board_size'] * config['board_size']

        while not done and moves < max_moves:
            valid_moves = env.get_valid_moves()

            if env.current_player == mcts_player:
                # MCTSè¡ŒåŠ¨
                action = mcts_ai.get_move(state, valid_moves)
            else:
                # å¯¹æ‰‹è¡ŒåŠ¨
                action = opponent.get_move(state, valid_moves)

            if action is None or valid_moves[action] == 0:
                # æ²¡æœ‰åˆæ³•ç§»åŠ¨ï¼Œå¹³å±€
                env.done = True
                env.winner = 0
                break

            state, reward, done, _ = env.step(action, env.current_player)
            moves += 1

            if done:
                if env.winner == mcts_player:
                    mcts_wins += 1
                elif env.winner == opponent_player:
                    opponent_wins += 1
                else:
                    draws += 1
                break

        # è®°å½•ç»Ÿè®¡
        game_time = (datetime.now() - start_time).total_seconds()

        stats['games'].append(game_idx + 1)
        stats['mcts_wins'].append(mcts_wins)
        stats['opponent_wins'].append(opponent_wins)
        stats['draws'].append(draws)
        stats['avg_moves'].append(moves)
        stats['training_time'].append(game_time)

        # å®šæœŸä¿å­˜å’Œæ˜¾ç¤º
        if (game_idx + 1) % config['log_interval'] == 0:
            total_played = mcts_wins + opponent_wins + draws
            if total_played > 0:
                mcts_win_rate = mcts_wins / total_played
                opponent_win_rate = opponent_wins / total_played
                draw_rate = draws / total_played

                print(f"\næ¸¸æˆ {game_idx + 1}/{config['total_games']}:")
                print(f"  MCTSèƒœç‡: {mcts_win_rate:.2%} ({mcts_wins}/{total_played})")
                print(f"  å¯¹æ‰‹èƒœç‡: {opponent_win_rate:.2%} ({opponent_wins}/{total_played})")
                print(f"  å¹³å±€ç‡: {draw_rate:.2%} ({draws}/{total_played})")
                print(f"  å¹³å‡æ­¥æ•°: {np.mean(stats['avg_moves'][-config['log_interval']:]):.1f}")
                print(f"  å¹³å‡æ—¶é—´/å±€: {np.mean(stats['training_time'][-config['log_interval']:]):.1f}s")

            # ä¿å­˜æ£€æŸ¥ç‚¹
            if (game_idx + 1) % config['save_interval'] == 0:
                checkpoint_path = os.path.join(save_dir, f"mcts_checkpoint_game{game_idx + 1}.pkl")
                with open(checkpoint_path, 'wb') as f:
                    pickle.dump({
                        'mcts_ai': mcts_ai,
                        'stats': stats,
                        'config': config
                    }, f)
                print(f"  ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")

    # æœ€ç»ˆè¯„ä¼°
    print("\n" + "=" * 60)
    print("è®­ç»ƒå®Œæˆï¼æœ€ç»ˆç»Ÿè®¡")
    print("=" * 60)

    total_played = mcts_wins + opponent_wins + draws
    if total_played > 0:
        print(f"MCTSæ€»èƒœç‡: {mcts_wins / total_played:.2%}")
        print(f"å¯¹æ‰‹æ€»èƒœç‡: {opponent_wins / total_played:.2%}")
        print(f"å¹³å±€ç‡: {draws / total_played:.2%}")
        print(f"å¹³å‡æ­¥æ•°: {np.mean(stats['avg_moves']):.1f}")

    # ä¿å­˜æœ€ç»ˆæ¨¡å‹
    final_path = os.path.join(save_dir, "mcts_final.pkl")
    with open(final_path, 'wb') as f:
        pickle.dump({
            'mcts_ai': mcts_ai,
            'stats': stats,
            'config': config
        }, f)

    print(f"\nâœ… æœ€ç»ˆæ¨¡å‹ä¿å­˜åˆ°: {final_path}")

    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    plot_training_curves(stats, save_dir, config)

    return mcts_ai, stats, save_dir


def plot_training_curves(stats, save_dir, config):
    """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
    plt.figure(figsize=(15, 10))

    # èƒœç‡æ›²çº¿
    plt.subplot(2, 3, 1)
    games = stats['games']

    if len(games) > 0:
        mcts_win_rates = [m / t if t > 0 else 0 for m, t in zip(stats['mcts_wins'], games)]
        opponent_win_rates = [o / t if t > 0 else 0 for o, t in zip(stats['opponent_wins'], games)]
        draw_rates = [d / t if t > 0 else 0 for d, t in zip(stats['draws'], games)]

        plt.plot(games, mcts_win_rates, 'g-', label='MCTSèƒœç‡', linewidth=2)
        plt.plot(games, opponent_win_rates, 'r-', label='å¯¹æ‰‹èƒœç‡', linewidth=2)
        plt.plot(games, draw_rates, 'b-', label='å¹³å±€ç‡', linewidth=2)

        plt.xlabel('æ¸¸æˆå±€æ•°')
        plt.ylabel('èƒœç‡')
        plt.title('èƒœç‡æ›²çº¿')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.ylim(0, 1)

    # ç´¯è®¡èƒœç‡
    plt.subplot(2, 3, 2)
    if len(games) > 0:
        window = 50
        if len(mcts_win_rates) > window:
            smoothed = np.convolve(mcts_win_rates, np.ones(window) / window, mode='valid')
            plt.plot(range(window - 1, len(games)), smoothed, 'g-', linewidth=2, label='MCTSèƒœç‡(å¹³æ»‘)')
        plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='50%åŸºå‡†')
        plt.xlabel('æ¸¸æˆå±€æ•°')
        plt.ylabel('èƒœç‡(å¹³æ»‘)')
        plt.title('MCTSèƒœç‡(å¹³æ»‘)')
        plt.legend()
        plt.grid(True, alpha=0.3)

    # å¹³å‡æ­¥æ•°
    plt.subplot(2, 3, 3)
    if len(stats['avg_moves']) > 0:
        plt.plot(games, stats['avg_moves'], 'c-', alpha=0.5)

        # å¹³æ»‘
        window = 20
        if len(stats['avg_moves']) > window:
            smoothed_moves = np.convolve(stats['avg_moves'], np.ones(window) / window, mode='valid')
            plt.plot(range(window - 1, len(games)), smoothed_moves, 'b-', linewidth=2, label='å¹³æ»‘')

        plt.xlabel('æ¸¸æˆå±€æ•°')
        plt.ylabel('æ­¥æ•°')
        plt.title('å¹³å‡æ­¥æ•°')
        plt.grid(True, alpha=0.3)

    # æ—¶é—´ç»Ÿè®¡
    plt.subplot(2, 3, 4)
    if len(stats['training_time']) > 0:
        plt.plot(games, stats['training_time'], 'y-', alpha=0.3)

        window = 20
        if len(stats['training_time']) > window:
            smoothed_time = np.convolve(stats['training_time'], np.ones(window) / window, mode='valid')
            plt.plot(range(window - 1, len(games)), smoothed_time, 'orange', linewidth=2, label='å¹³æ»‘')

        plt.xlabel('æ¸¸æˆå±€æ•°')
        plt.ylabel('æ—¶é—´(ç§’)')
        plt.title('æ¯å±€è®­ç»ƒæ—¶é—´')
        plt.grid(True, alpha=0.3)

    # èƒœè´Ÿç»Ÿè®¡æŸ±çŠ¶å›¾
    plt.subplot(2, 3, 5)
    if len(games) > 0:
        labels = ['MCTSèƒœåˆ©', 'å¯¹æ‰‹èƒœåˆ©', 'å¹³å±€']
        values = [stats['mcts_wins'][-1], stats['opponent_wins'][-1], stats['draws'][-1]]
        colors = ['green', 'red', 'blue']

        bars = plt.bar(labels, values, color=colors)
        plt.ylabel('å±€æ•°')
        plt.title('èƒœè´Ÿç»Ÿè®¡')

        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, values):
            plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 1,
                     f'{value}', ha='center', va='bottom')

    # è®­ç»ƒä¿¡æ¯
    plt.subplot(2, 3, 6)
    plt.axis('off')

    info_text = f"è®­ç»ƒé…ç½®:\n"
    info_text += f"æ£‹ç›˜å¤§å°: {config['board_size']}x{config['board_size']}\n"
    info_text += f"å¯¹æ‰‹: {config['opponent_type']}\n"
    info_text += f"è®­ç»ƒå±€æ•°: {config['total_games']}\n"
    info_text += f"æœç´¢æ¬¡æ•°/æ­¥: {config['iterations_per_move']}\n"

    if len(games) > 0:
        info_text += f"\næœ€ç»ˆç»Ÿè®¡:\n"
        info_text += f"MCTSèƒœç‡: {stats['mcts_wins'][-1] / games[-1]:.2%}\n"
        info_text += f"å¯¹æ‰‹èƒœç‡: {stats['opponent_wins'][-1] / games[-1]:.2%}\n"
        info_text += f"å¹³å±€ç‡: {stats['draws'][-1] / games[-1]:.2%}\n"
        info_text += f"å¹³å‡æ­¥æ•°: {np.mean(stats['avg_moves']):.1f}\n"

    plt.text(0.1, 0.9, info_text, fontsize=10, verticalalignment='top')

    plt.suptitle(f"MCTSè®­ç»ƒç»“æœ - å¯¹æ‰‹: {config['opponent_type']}", fontsize=16)
    plt.tight_layout()

    plot_path = os.path.join(save_dir, "training_curves.png")
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"ğŸ“ˆ è®­ç»ƒæ›²çº¿ä¿å­˜åˆ°: {plot_path}")


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # æ ¹æ®æ‚¨çš„DQNè¡¨ç°é€‰æ‹©è®­ç»ƒç­–ç•¥

    # æ–¹æ¡ˆAï¼šå¦‚æœDQNè¡¨ç°ä¸€èˆ¬ï¼ˆ<60%èƒœç‡ï¼‰ï¼Œå…ˆç”¨è§„åˆ™AIè®­ç»ƒ
    if True:  # æ›¿æ¢ä¸ºæ‚¨çš„åˆ¤æ–­æ¡ä»¶
        print("ä½¿ç”¨æ–¹æ¡ˆAï¼šMCTS vs è§„åˆ™AIï¼ˆå¿«é€Ÿå¯åŠ¨ï¼‰")
        config = {
            'board_size': 9,
            'opponent_type': 'rule_based',  # ä½¿ç”¨è§„åˆ™AI
            'opponent_aggression': 0.5,  # ä¸­ç­‰éš¾åº¦
            'iterations_per_move': 500,  # æ¯æ­¥æœç´¢æ¬¡æ•°
            'total_games': 1000,  # è®­ç»ƒå±€æ•°
            'log_interval': 50,  # æ—¥å¿—é—´éš”
            'save_interval': 200,  # ä¿å­˜é—´éš”
            'save_dir': 'saved_models/mcts',
            'debug': False
        }

    # æ–¹æ¡ˆBï¼šå¦‚æœDQNè¡¨ç°ä¼˜ç§€ï¼ˆ>60%èƒœç‡ï¼‰ï¼Œç”¨DQNè®­ç»ƒ
    else:
        print("ä½¿ç”¨æ–¹æ¡ˆBï¼šMCTS vs DQNï¼ˆå¼ºåŒ–è®­ç»ƒï¼‰")
        config = {
            'board_size': 9,
            'opponent_type': 'dqn',  # ä½¿ç”¨DQN
            'dqn_model_path': 'saved_models/dqn_final.pth',  # DQNæ¨¡å‹è·¯å¾„
            'iterations_per_move': 800,  # å¢åŠ æœç´¢æ·±åº¦
            'total_games': 2000,  # æ›´å¤šè®­ç»ƒå±€æ•°
            'log_interval': 100,
            'save_interval': 500,
            'save_dir': 'saved_models/mcts_vs_dqn',
            'debug': False
        }

    # å¼€å§‹è®­ç»ƒ
    try:
        mcts_ai, stats, save_dir = train_mcts_with_opponent(config)

        # æœ€ç»ˆè¯„ä¼°æŠ¥å‘Š
        report_path = os.path.join(save_dir, "training_report.txt")
        with open(report_path, 'w') as f:
            f.write("MCTSè®­ç»ƒæŠ¥å‘Š\n")
            f.write("=" * 40 + "\n")
            f.write(f"è®­ç»ƒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"å¯¹æ‰‹ç±»å‹: {config['opponent_type']}\n")
            f.write(f"è®­ç»ƒå±€æ•°: {len(stats['games'])}\n")

            if len(stats['games']) > 0:
                total_games = stats['games'][-1]
                mcts_wins = stats['mcts_wins'][-1]
                opponent_wins = stats['opponent_wins'][-1]
                draws = stats['draws'][-1]

                f.write(f"MCTSèƒœç‡: {mcts_wins / total_games:.2%}\n")
                f.write(f"å¯¹æ‰‹èƒœç‡: {opponent_wins / total_games:.2%}\n")
                f.write(f"å¹³å±€ç‡: {draws / total_games:.2%}\n")
                f.write(f"å¹³å‡æ­¥æ•°: {np.mean(stats['avg_moves']):.1f}\n")
                f.write(f"æ¨¡å‹ä¿å­˜ç›®å½•: {save_dir}\n")

        print(f"\nğŸ“„ è®­ç»ƒæŠ¥å‘Šä¿å­˜åˆ°: {report_path}")

    except KeyboardInterrupt:
        print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()